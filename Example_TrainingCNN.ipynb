{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, nibabel as nib, numpy as np\n",
    "sys.path.insert(0, 'core/')\n",
    "from epi import  data_prep_ml\n",
    "from utils import imask_ut\n",
    "from denoiser import cnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.draw import circle\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ts = \" \" # Path of the ground truth in nifti format.\n",
    "measured_fmri_ts = \" \" # Path of the extracted measured fMRI time series in nifti format. \n",
    "masks = \" \" # Path of the saved masks of the extracted slices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Output Files - Trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Before CNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs no input if using the standard motion sequences preprogrammed for BrainDancer. If using custom sequences, provide the number of moving volumes to the data_prep_ml function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_fmri = nib.load(measured_fmri_ts)\n",
    "ground_truth = nib.load(ground_truth_ts)\n",
    "imask = nib.load(masks)\n",
    "imask_utils = imask_ut(imask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stack_scn refers to the stack of measured fMRI time series\n",
    "## stack_sim refers to the stack of ground truth time series\n",
    "stack_scn, stack_sim, noise, stack_scn_flip, stack_sim_flip, noise_flip = data_prep_ml(ground_truth,measured_fmri,imask_utils,1,600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 250 # Enter the number of epochs for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.concatenate(((stack_scn/np.std(stack_scn,axis=1)[:,None]).reshape((len(stack_scn),600,1)),(stack_scn_flip/np.std(stack_scn,axis=1)[:,None]).reshape((len(stack_scn),600,1))))\n",
    "output_data = np.concatenate(((stack_sim).reshape((len(stack_sim),600,1)),(stack_sim_flip).reshape((len(stack_sim),600,1))))\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.33, random_state=42)\n",
    "ml = cnn(600)\n",
    "filepath = Output + \"/save_ml.h5\"\n",
    "mc = ModelCheckpoint(filepath, verbose=1, monitor= 'val_custom_loss',save_best_only=True)\n",
    "history = ml.fit(X_train,y_train, nb_epoch = num_epochs, batch_size = 8,verbose=1, validation_data = (X_test,y_test),callbacks=[mc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
